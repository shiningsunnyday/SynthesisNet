{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CCNS(=O)(=O)c1cc([N+](=O)[O-])ccc1C1=NC(c2ccc(N=C=O)cc2F)=NN1',\n",
       " 'COC(=O)c1ccc(NC(=O)Nc2ccc(C#N)nc2)c(O)c1',\n",
       " 'Nc1c(Cl)cc(F)cc1C1=NC(c2cc([N+](=O)[O-])c(F)cc2F)=NN1',\n",
       " 'CC(=O)N(c1nc(CNC(=S)Nc2cc(Br)cc(Cl)c2C(=O)O)cs1)c1c(C)cc(C)cc1Cl',\n",
       " 'COC(=O)c1ccc(OCCNC(=O)CN=C=S)c(N)c1F',\n",
       " 'CC(C)(C)c1ccc2c(c1)C(=O)NC(CN=C=S)=N2',\n",
       " 'CC(C)Nc1ccc(Cl)cc1NS(=O)(=O)Cc1cc(F)ccc1[N+](=O)[O-]',\n",
       " 'CCCn1c(-c2cc(Cl)cc(Cl)c2[N+](=O)[O-])nc2ccccc21',\n",
       " 'COCCOc1cc(NS(=O)(=O)Cc2cc(F)ccc2[N+](=O)[O-])c(C(=O)O)cc1OC',\n",
       " 'Cc1ccc(N=C=O)c(C2=NNC(Cc3ccc(N=C=S)cc3)=N2)c1']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "import os\n",
    "\n",
    "\n",
    "data = pickle.load(open('SynthesisNet/results/viz/top_1000/skeletons-top-1000-valid.pkl', 'rb'))\n",
    "inds = [0,1,2,3,15,20,22,32,47,60,61,62,64,65,68,72,96,104,156,245,292,295,525,540,812,958,1107,2024,2252,6180]\n",
    "sts = [list(data)[ind] for ind in inds]\n",
    "smiles = []\n",
    "for st in sts:\n",
    "    for st in data[st]:\n",
    "        assert len(st.reactions) <= 4\n",
    "        smiles.append(st.root.smiles)\n",
    "\n",
    "smiles[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(smiles)\n",
    "with open('SynthesisNet/data/assets/molecules/depth-5.txt', 'w+') as f:\n",
    "    for smile in smiles:\n",
    "        f.write(f\"{smile}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "lines = open('SynthesisNet/output_mcmc_drd2_top_k=3_max_num_rxns=3.txt.txt').readlines()\n",
    "all_scores = []\n",
    "all_smiles = []\n",
    "all_indices = []\n",
    "for line in lines:\n",
    "    index, smiles, score_history, smiles_history, index_history = line.split()\n",
    "    all_scores.append(list(map(float, score_history.split(','))))\n",
    "    all_smiles.append(smiles_history.split(','))\n",
    "    all_indices.append(list(map(int, index_history.split(','))))\n",
    "all_scores = np.array(all_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], dtype=float64)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# keys = []\n",
    "# for line in lines:\n",
    "#     keys.append([])\n",
    "#     all_smiles = line.split()[-2].split(',')\n",
    "#     all_indices = line.split()[-1].split(',')\n",
    "#     for smiles, indices in zip(all_smiles, all_indices):\n",
    "#         keys[-1].append((smiles, indices))\n",
    "# [len(set(key)) for key in keys]\n",
    "all_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4150332/3426805752.py:6: RuntimeWarning: Mean of empty slice.\n",
      "  max_top_k = all_scores_flatten[all_scores_flatten.argsort()[-k:]].mean(axis=-1)\n",
      "/tmp/ipykernel_4150332/3426805752.py:9: RuntimeWarning: Mean of empty slice.\n",
      "  max_mean = max_accum.mean(axis=0)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "object of type 'numpy.float64' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[53], line 11\u001b[0m\n\u001b[1;32m      9\u001b[0m max_mean \u001b[38;5;241m=\u001b[39m max_accum\u001b[38;5;241m.\u001b[39mmean(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     10\u001b[0m max_std \u001b[38;5;241m=\u001b[39m max_accum\u001b[38;5;241m.\u001b[39mstd(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m---> 11\u001b[0m x \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmax_mean\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     12\u001b[0m ax\u001b[38;5;241m.\u001b[39mplot(x, max_mean, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMean\u001b[39m\u001b[38;5;124m'\u001b[39m, color\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mblue\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     13\u001b[0m ax\u001b[38;5;241m.\u001b[39mfill_between(x, max_mean\u001b[38;5;241m-\u001b[39mmax_std, max_mean\u001b[38;5;241m+\u001b[39mmax_std, color\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mblue\u001b[39m\u001b[38;5;124m'\u001b[39m, alpha\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mStandard Deviation\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'numpy.float64' has no len()"
     ]
    }
   ],
   "source": [
    "fig = plt.Figure()\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "max_accum = np.maximum.accumulate(all_scores, axis=-1)\n",
    "for k in [1,3,10,100]:\n",
    "    all_scores_flatten = all_scores.flatten()\n",
    "    max_top_k = all_scores_flatten[all_scores_flatten.argsort()[-k:]].mean(axis=-1)\n",
    "    ax.axhline(max_top_k, label=f'Top {k}={max_top_k}', color='purple')\n",
    "\n",
    "max_mean = max_accum.mean(axis=0)\n",
    "max_std = max_accum.std(axis=0)\n",
    "x = np.arange(len(max_mean))\n",
    "ax.plot(x, max_mean, label='Mean', color='blue')\n",
    "ax.fill_between(x, max_mean-max_std, max_mean+max_std, color='blue', alpha=0.2, label='Standard Deviation')\n",
    "\n",
    "ax.legend()\n",
    "fig.savefig(\"test.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 21)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_scores.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'SynthesisNet/output_reconstruct_top_k=3_max_num_rxns=4_max_rxns=-1.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[41], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msynnet\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfig\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DELIM\n\u001b[0;32m----> 2\u001b[0m lines \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mSynthesisNet/output_reconstruct_top_k=3_max_num_rxns=4_max_rxns=-1.txt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mreadlines()\n\u001b[1;32m      3\u001b[0m recovered \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtargets\u001b[39m\u001b[38;5;124m'\u001b[39m: [], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdecoded\u001b[39m\u001b[38;5;124m'\u001b[39m: []}\n\u001b[1;32m      4\u001b[0m unrecovered \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtargets\u001b[39m\u001b[38;5;124m'\u001b[39m: [], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdecoded\u001b[39m\u001b[38;5;124m'\u001b[39m: []}\n",
      "File \u001b[0;32m~/miniconda3/envs/synnet/lib/python3.9/site-packages/IPython/core/interactiveshell.py:284\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    278\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    279\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    280\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    281\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    282\u001b[0m     )\n\u001b[0;32m--> 284\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'SynthesisNet/output_reconstruct_top_k=3_max_num_rxns=4_max_rxns=-1.txt'"
     ]
    }
   ],
   "source": [
    "from synnet.config import DELIM\n",
    "lines = open('SynthesisNet/output_reconstruct_top_k=3_max_num_rxns=4_max_rxns=-1.txt').readlines()\n",
    "recovered = {'targets': [], 'decoded': []}\n",
    "unrecovered = {'targets': [], 'decoded': []}\n",
    "scores = []\n",
    "for line in lines:\n",
    "    index, res, score = line.split(' ')\n",
    "    target, decoded, index = res.split(DELIM)\n",
    "    score = float(score)\n",
    "    if score == 1.0:\n",
    "        recovered['targets'].append(target)\n",
    "        recovered['decoded'].append(decoded)\n",
    "    else:\n",
    "        unrecovered['targets'].append(target)\n",
    "        unrecovered['decoded'].append(decoded)\n",
    "    scores.append(score)\n",
    "\n",
    "\n",
    "print(np.mean(scores), (np.array(scores)==1).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation metric for kl_divergence:\n",
      "    Recovered score: 1.00\n",
      "  Unrecovered score: 0.89\n",
      "  Total score: 0.96\n",
      "Evaluation metric for fcd_distance:\n",
      "    Recovered score: 0.00\n",
      "  Unrecovered score: 1.79\n",
      "  Total score: 0.46\n",
      "Evaluation metric for novelty:\n",
      "    Recovered score: 0.01\n",
      "  Unrecovered score: 1.00\n",
      "  Total score: 0.50\n",
      "Evaluation metric for validity:\n",
      "    Recovered score: 1.00\n",
      "  Unrecovered score: 1.00\n",
      "  Total score: 1.00\n",
      "Evaluation metric for uniqueness:\n",
      "    Recovered score: 1.00\n",
      "  Unrecovered score: 1.00\n",
      "  Total score: 1.00\n"
     ]
    }
   ],
   "source": [
    "from tdc import Evaluator\n",
    "\n",
    "for metric in \"KL_divergence FCD_Distance Novelty Validity Uniqueness\".split():\n",
    "    evaluator = Evaluator(name=metric)\n",
    "    try:\n",
    "        score_recovered = evaluator(recovered[\"targets\"], recovered[\"decoded\"])\n",
    "        score_unrecovered = evaluator(unrecovered[\"targets\"], unrecovered[\"decoded\"])\n",
    "        score_all = evaluator(recovered[\"targets\"]+unrecovered['targets'], recovered[\"decoded\"]+unrecovered['decoded'])\n",
    "    except TypeError:\n",
    "        # Some evaluators only take 1 input args, try that.\n",
    "        score_recovered = evaluator(recovered[\"decoded\"])\n",
    "        score_unrecovered = evaluator(unrecovered[\"decoded\"])\n",
    "        score_all = evaluator(recovered[\"decoded\"]+unrecovered['decoded'])\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        score_recovered, score_unrecovered = np.nan, np.nan\n",
    "\n",
    "    print(f\"Evaluation metric for {evaluator.name}:\")\n",
    "    print(f\"    Recovered score: {score_recovered:.2f}\")\n",
    "    print(f\"  Unrecovered score: {score_unrecovered:.2f}\")\n",
    "    print(f\"  Total score: {score_all:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0 CC(C)(C)OC(=O)N1CC(CCl)(C2=NN(C3(C(=O)O)CCOC3c3ccc(F)cc3)N=N2)C1_____CC(C)(C)OC(=O)N1CC(CCl)(C2=NN(CC(=O)N3CCOC(c4ccc(F)cc4)C3)N=N2)C1_____1 0.573170731707317\\n'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = Evaluator(name='FCD_Distance')\n",
    "evaluator(recovered[\"decoded\"], recovered[\"targets\"]+unrecovered[\"targets\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = Evaluator(name='FCD_Distance')\n",
    "evaluator(recovered[\"decoded\"], recovered[\"targets\"]+unrecovered[\"targets\"])\n",
    "evaluator = Evaluator(name='KL_divergence')\n",
    "evaluator(recovered[\"decoded\"], recovered[\"targets\"]+unrecovered[\"targets\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "synnet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
